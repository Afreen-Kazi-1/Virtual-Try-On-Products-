{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6683799,"sourceType":"datasetVersion","datasetId":3855472}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Installing Packages\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2 as cv2\n\n# Check TensorFlow version\n\nprint(tf.__version__)\nprint (cv2.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T10:33:34.611960Z","iopub.execute_input":"2024-09-15T10:33:34.612861Z","iopub.status.idle":"2024-09-15T10:33:48.866780Z","shell.execute_reply.started":"2024-09-15T10:33:34.612801Z","shell.execute_reply":"2024-09-15T10:33:48.865585Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"2.16.1\n4.10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"try:\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\nexcept:\n    print(\"TensorFlow setup not working correctly.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T10:33:48.869094Z","iopub.execute_input":"2024-09-15T10:33:48.870191Z","iopub.status.idle":"2024-09-15T10:33:48.878219Z","shell.execute_reply.started":"2024-09-15T10:33:48.870135Z","shell.execute_reply":"2024-09-15T10:33:48.876943Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Num GPUs Available:  0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load Array of data","metadata":{}},{"cell_type":"code","source":"import os as os\n# Directory paths\nperson_images_dir = '/kaggle/input/high-resolution-viton-zalando-dataset/test/agnostic-v3.2'\ncloth_images_dir = '/kaggle/input/high-resolution-viton-zalando-dataset/test/cloth'\nmask_images_dir = '/kaggle/input/high-resolution-viton-zalando-dataset/test/image-parse-v3'\noutput_images_dir= '/kaggle/input/high-resolution-viton-zalando-dataset/test/image'\n\n# Load all images in the directory\nperson_images = []\ncloth_images = []\nmask_images = []\noutput_images = []\n\nfor person_filename, cloth_filename , mask_filename, output_filename in zip(sorted(os.listdir(person_images_dir)), sorted(os.listdir(cloth_images_dir)), sorted (os.listdir(mask_images_dir)), sorted(os.listdir(output_images_dir))):\n    person_img_path = os.path.join(person_images_dir, person_filename)\n    cloth_img_path = os.path.join(cloth_images_dir, cloth_filename)\n    mask_img_path = os.path.join(mask_images_dir, mask_filename)\n    output_img_path = os.path.join(output_images_dir, output_filename)\n    \n    # Load, resize, and normalize the images\n    person_image = cv2.imread(person_img_path)\n    person_image = cv2.cvtColor(person_image, cv2.COLOR_BGR2RGB)\n    person_image = cv2.resize(person_image, (128,128)) / 255.0\n    \n    cloth_image = cv2.imread(cloth_img_path)\n    cloth_image = cv2.cvtColor(cloth_image, cv2.COLOR_BGR2RGB)\n    cloth_image = cv2.resize(cloth_image, (128,128)) / 255.0\n    \n    mask_image = cv2.imread(mask_img_path)\n    mask_image = cv2.cvtColor(mask_image, cv2.COLOR_BGR2RGB)\n    mask_image = cv2.resize(mask_image, (128,128)) / 255.0\n    mask_image = np.mean(mask_image, axis=-1, keepdims=True)\n    \n    output_image = cv2.imread(output_img_path)\n    output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n    output_image = cv2.resize(output_image, (128,128)) / 255.0\n    \n    person_images.append(person_image)\n    cloth_images.append(cloth_image)\n    mask_images.append(mask_image)\n    output_images.append(output_image)\n\n# Convert to numpy arrays\nperson_images = np.array(person_images)\ncloth_images = np.array(cloth_images)\nmask_images = np.array(mask_images)\noutput_images = np.array(output_images)\n\n# Print the shape of the arrays to verify\nprint(f\"Loaded {person_images.shape[0]} person images.\")\nprint(f\"Loaded {cloth_images.shape[0]} cloth images.\")\nprint(f\"Loaded {mask_images.shape[0]} mask images.\")\nprint(f\"Loaded {output_images.shape[0]} output images.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T10:39:43.627753Z","iopub.execute_input":"2024-09-15T10:39:43.628242Z","iopub.status.idle":"2024-09-15T10:41:23.981905Z","shell.execute_reply.started":"2024-09-15T10:39:43.628203Z","shell.execute_reply":"2024-09-15T10:41:23.980766Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Loaded 2032 person images.\nLoaded 2032 cloth images.\nLoaded 2032 mask images.\nLoaded 2032 output images.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Build the deepUnet model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers, models, losses, applications\nimport tensorflow as tf\n\n\n# Using VGG19 for perceptual loss\n# vgg = applications.VGG19(include_top=False, weights='imagenet', input_shape=(128, 128, 3))\n# def perceptual_loss(y_true, y_pred):\n#     vgg.trainable = False\n#     feature_extractor = models.Model(inputs=vgg.input, outputs=[vgg.get_layer('block5_conv4').output])\n\n#     y_true_features = feature_extractor(y_true)\n#     y_pred_features = feature_extractor(y_pred)\n\n#     return tf.reduce_mean(tf.square(y_true_features - y_pred_features))\n\ndef build_unet_virtual_tryon_model():\n    inputs_person = layers.Input(shape=(128, 128, 3))\n    inputs_cloth = layers.Input(shape=(128, 128, 3))\n    inputs_mask = layers.Input(shape=(128, 128, 1))\n\n    # Encoder for person image\n    x_person_og = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs_person)\n    x_person_skip = layers.MaxPooling2D((2, 2))(x_person_og)\n    x_person = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x_person_skip)\n    x_person = layers.MaxPooling2D((2, 2))(x_person)\n    x_person = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x_person)\n    x_person = layers.MaxPooling2D((2, 2))(x_person)\n\n    # Encoder for cloth image\n    x_cloth_og = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs_cloth)\n    x_cloth_skip = layers.MaxPooling2D((2, 2))(x_cloth_og)\n    x_cloth = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x_cloth_skip)\n    x_cloth_2 = layers.MaxPooling2D((2, 2))(x_cloth)\n    x_cloth = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x_cloth_2)\n    x_cloth = layers.MaxPooling2D((2, 2))(x_cloth)\n\n    # Encoder for segmentation mask\n    x_mask_og = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs_mask)\n    x_mask_skip = layers.MaxPooling2D((2, 2))(x_mask_og)\n    x_mask = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x_mask_skip)\n    x_mask = layers.MaxPooling2D((2, 2))(x_mask)\n    x_mask = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x_mask)\n    x_mask = layers.MaxPooling2D((2, 2))(x_mask)\n\n    # Concatenate features from all branches\n    concatenated = layers.concatenate([x_person, x_cloth, x_mask], axis=-1)\n\n    # Decoder part with skip connections\n    x = layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(concatenated)\n    x = layers.concatenate([x, x_cloth_2], axis=-1)\n    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n\n    x = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(x)\n    print(x.shape)\n    x = layers.concatenate([x, x_cloth_skip], axis=-1)\n    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n\n    x = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.concatenate([x, x_person_og], axis=-1)\n    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n\n    # Output layer\n    output_image = layers.Conv2D(3, (1, 1), activation='sigmoid')(x)\n\n    # Build and compile the model\n    model = models.Model(inputs=[inputs_person, inputs_cloth, inputs_mask], outputs=output_image)\n    model.compile(optimizer='adam', loss='mse')\n\n    return model\n\nmodel_deepunet = build_unet_virtual_tryon_model()\nmodel_deepunet.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T10:41:38.614139Z","iopub.execute_input":"2024-09-15T10:41:38.614592Z","iopub.status.idle":"2024-09-15T10:41:42.028327Z","shell.execute_reply.started":"2024-09-15T10:41:38.614548Z","shell.execute_reply":"2024-09-15T10:41:42.027273Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n(None, 64, 64, 128)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m1,792\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m1,792\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m640\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_6[\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_4[\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_7[\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m768\u001b[0m)              │            │ max_pooling2d_5[\u001b[38;5;34m…\u001b[0m │\n│                     │                   │            │ max_pooling2d_8[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_transpose    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │  \u001b[38;5;34m1,769,728\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m384\u001b[0m)              │            │ max_pooling2d_4[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m884,992\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_transpose_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m295,040\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ max_pooling2d_3[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m221,312\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_transpose_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │     \u001b[38;5;34m73,792\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │     \u001b[38;5;34m73,792\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m195\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)              │            │ max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │                   │            │ max_pooling2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_transpose    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,769,728</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              │            │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_transpose_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">221,312</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_transpose_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,430,147\u001b[0m (16.90 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,430,147</span> (16.90 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,430,147\u001b[0m (16.90 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,430,147</span> (16.90 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Train the model","metadata":{}},{"cell_type":"code","source":"X_person = np.array(person_images)\nX_cloth = np.array(cloth_images)\nY_output = np.array(output_images)\n\n# Now the shape of segmentation_image will be (256, 256, 1)\nX_segmentation = np.array(mask_images)\n\nmodel_deepunet.fit([X_person, X_cloth, X_segmentation], Y_output, epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T10:42:30.544239Z","iopub.execute_input":"2024-09-15T10:42:30.544744Z","iopub.status.idle":"2024-09-15T14:11:25.005580Z","shell.execute_reply.started":"2024-09-15T10:42:30.544667Z","shell.execute_reply":"2024-09-15T14:11:24.999880Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m850s\u001b[0m 13s/step - loss: 0.0630\nEpoch 2/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m821s\u001b[0m 13s/step - loss: 0.0199\nEpoch 3/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m823s\u001b[0m 13s/step - loss: 0.0150\nEpoch 4/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 13s/step - loss: 0.0121\nEpoch 5/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m855s\u001b[0m 13s/step - loss: 0.0110\nEpoch 6/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m861s\u001b[0m 13s/step - loss: 0.0096\nEpoch 7/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m818s\u001b[0m 13s/step - loss: 0.0091\nEpoch 8/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m864s\u001b[0m 13s/step - loss: 0.0082\nEpoch 9/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m859s\u001b[0m 13s/step - loss: 0.0085\nEpoch 10/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m818s\u001b[0m 13s/step - loss: 0.0076\nEpoch 11/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m862s\u001b[0m 13s/step - loss: 0.0074\nEpoch 12/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 13s/step - loss: 0.0072\nEpoch 13/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m818s\u001b[0m 13s/step - loss: 0.0067\nEpoch 14/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m818s\u001b[0m 13s/step - loss: 0.0067\nEpoch 15/15\n\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m820s\u001b[0m 13s/step - loss: 0.0067\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7880918777f0>"},"metadata":{}}]},{"cell_type":"code","source":"model_deepunet.save('deepunet_model.h5')  # Save the model in HDF5 format","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:51:08.172625Z","iopub.execute_input":"2024-09-15T14:51:08.174288Z","iopub.status.idle":"2024-09-15T14:51:08.494369Z","shell.execute_reply.started":"2024-09-15T14:51:08.174221Z","shell.execute_reply":"2024-09-15T14:51:08.493331Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Verify that the model can run one epoch of training\ntest_loss = model_unet.evaluate([X_person, X_cloth, X_segmentation], Y_output)\nprint(f\"Test Loss after one epoch: {test_loss}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:27:19.62676Z","iopub.execute_input":"2024-09-10T04:27:19.627231Z","iopub.status.idle":"2024-09-10T04:28:48.270544Z","shell.execute_reply.started":"2024-09-10T04:27:19.627185Z","shell.execute_reply":"2024-09-10T04:28:48.269112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize output","metadata":{}},{"cell_type":"code","source":"# Test the model on the same input\nmodel_deep_unet = deepunet_model.h5\npredicted_image = model_deepunet.predict([X_person, X_cloth, X_segmentation])\n\nnp.save('predicted_image.npy', predicted_image)\n\n# Display the original and predicted images\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 3, 1)\nplt.title(\"Cloth Image\")\nplt.imshow(X_person[1])\n\nplt.subplot(1, 3, 2)\nplt.title(\"Output Image\")\nplt.imshow(Y_output[1])\n\nplt.subplot(1, 3, 3)\nplt.title(\"Predicted Try-On Image\")\nplt.imshow(predicted_image[1])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-15T17:28:54.370658Z","iopub.execute_input":"2024-09-15T17:28:54.371287Z","iopub.status.idle":"2024-09-15T17:28:54.428529Z","shell.execute_reply.started":"2024-09-15T17:28:54.371231Z","shell.execute_reply":"2024-09-15T17:28:54.426639Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test the model on the same input\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_deep_unet \u001b[38;5;241m=\u001b[39m \u001b[43mdeepunet_model\u001b[49m\u001b[38;5;241m.\u001b[39mh5\n\u001b[1;32m      3\u001b[0m predicted_image \u001b[38;5;241m=\u001b[39m model_deepunet\u001b[38;5;241m.\u001b[39mpredict([X_person, X_cloth, X_segmentation])\n\u001b[1;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_image.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, predicted_image)\n","\u001b[0;31mNameError\u001b[0m: name 'deepunet_model' is not defined"],"ename":"NameError","evalue":"name 'deepunet_model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# from tensorflow.keras.losses import MeanSquaredError\n\n# mse = MeanSquaredError()\n# mse_value = mse(Y_output_test, predictions).numpy()\n# print(f'MSE: {mse_value}')\n\ndef psnr(target, prediction):\n    mse = np.mean((target - prediction) ** 2)\n    return 10 * np.log10(1.0 / mse)\n\npsnr = psnr(Y_output, predicted_image)\nprint(psnr)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:11:40.987770Z","iopub.execute_input":"2024-09-15T15:11:40.989598Z","iopub.status.idle":"2024-09-15T15:11:42.016724Z","shell.execute_reply.started":"2024-09-15T15:11:40.989546Z","shell.execute_reply":"2024-09-15T15:11:42.015329Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"22.09979957786572\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Genertating agnostic from output image (testing purpose)\n## Can be ignored as GANs are computationally Expensive and might crash the session.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Concatenate\n\ndef build_generator(input_shape=(128, 128, 3), mask_shape=(128, 128, 1)):\n    person_input = Input(shape=input_shape, name='person_input')\n    mask_input = Input(shape=mask_shape, name='mask_input')\n    \n    # Combine person image and mask as input\n    combined_input = Concatenate()([person_input, mask_input])\n\n    x = layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same')(combined_input)\n    x = layers.LeakyReLU()(x)\n    \n    x = layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    \n    x = layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    \n    x = layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    \n    x = layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    \n    output = layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', activation='tanh')(x)\n    \n    model = tf.keras.Model(inputs=[person_input, mask_input], outputs=output)\n    return model\n\ngenerator = build_generator()\ngenerator.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:57:42.561751Z","iopub.execute_input":"2024-09-10T04:57:42.562346Z","iopub.status.idle":"2024-09-10T04:57:42.743892Z","shell.execute_reply.started":"2024-09-10T04:57:42.562296Z","shell.execute_reply":"2024-09-10T04:57:42.742815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_discriminator(input_shape=(128, 128, 3), agnostic_shape=(128, 128, 3)):\n    person_input = Input(shape=input_shape, name='person_input')\n    agnostic_input = Input(shape=agnostic_shape, name='agnostic_input')\n\n    combined_input = Concatenate()([person_input, agnostic_input])\n\n    x = layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same')(combined_input)\n    x = layers.LeakyReLU()(x)\n\n    x = layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n\n    x = layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n\n    x = layers.Flatten()(x)\n    output = layers.Dense(1, activation='sigmoid')(x)\n\n    model = tf.keras.Model(inputs=[person_input, agnostic_input], outputs=output)\n    return model\n\ndiscriminator = build_discriminator()\ndiscriminator.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:57:46.047468Z","iopub.execute_input":"2024-09-10T04:57:46.047943Z","iopub.status.idle":"2024-09-10T04:57:46.167751Z","shell.execute_reply.started":"2024-09-10T04:57:46.047898Z","shell.execute_reply":"2024-09-10T04:57:46.166592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Define constants\nBATCH_SIZE = 64\nEPOCHS = 10\nNOISE_DIM = 100  # Define if using noise\n\n# Define the loss functions\ndef generator_loss(fake_output):\n    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(fake_output), fake_output)\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real_output), real_output)\n    fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(fake_output), fake_output)\n    return real_loss + fake_loss\n\n# Define optimizers\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n\n@tf.function\ndef train_step(predicted_image, cloth_images, mask_images):\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        # Generate agnostic clothing image from person and mask input\n        generated_cloths = generator([predicted_image, mask_images], training=True)\n\n        # Discriminator outputs\n        real_output = discriminator([predicted_image, cloth_images], training=True)\n        fake_output = discriminator([predicted_image, generated_cloths], training=True)\n\n        # Calculate losses\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    # Apply gradients\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n\ndef train(predicted_image, cloth_images, mask_images, epochs):\n    dataset_size = len(predicted_image)  # Fixed the variable name\n    for epoch in range(epochs):\n        for i in range(0, dataset_size, BATCH_SIZE):\n            predicted_batch = predicted_image[i:i+BATCH_SIZE]\n            cloth_batch = cloth_images[i:i+BATCH_SIZE]\n            mask_batch = mask_images[i:i+BATCH_SIZE]\n            train_step(predicted_batch, cloth_batch, mask_batch)\n        print(f'Epoch {epoch + 1} completed')\n\n# Start training\ntrain(predicted_image, cloth_images, mask_images, EPOCHS)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T05:12:24.504574Z","iopub.execute_input":"2024-09-10T05:12:24.505251Z","iopub.status.idle":"2024-09-10T05:46:27.969194Z","shell.execute_reply.started":"2024-09-10T05:12:24.505196Z","shell.execute_reply":"2024-09-10T05:46:27.967797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\n# Define constants\nBATCH_SIZE = 64\nEPOCHS = 5\nNOISE_DIM = 100  # Define if using noise\nOUTPUT_DIR = './generated_images'  # Directory to save generated images\n\n# Ensure output directory exists\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Define the loss functions\ndef generator_loss(fake_output):\n    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(fake_output), fake_output)\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real_output), real_output)\n    fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(fake_output), fake_output)\n    return real_loss + fake_loss\n\n# Define optimizers\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n\n@tf.function\ndef train_step(predicted_image, cloth_images, mask_images):\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        # Generate agnostic clothing image from person and mask input\n        generated_cloths = generator([predicted_image, mask_images], training=True)\n\n        # Discriminator outputs\n        real_output = discriminator([predicted_image, cloth_images], training=True)\n        fake_output = discriminator([predicted_image, generated_cloths], training=True)\n\n        # Calculate losses\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    # Apply gradients\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n\ndef save_images(images, epoch, step):\n    \"\"\"\n    Saves a batch of images to disk.\n    \n    Args:\n        images (numpy.ndarray): Batch of images to save.\n        epoch (int): Current epoch number.\n        step (int): Current step number in the epoch.\n    \"\"\"\n    images = (images * 127.5 + 127.5).astype(np.uint8)  # Denormalize images to 0-255 range\n    for i, img in enumerate(images):\n        plt.imsave(f\"{OUTPUT_DIR}/image_epoch_{epoch:03d}_step_{step:04d}_{i:03d}.png\", img)\n\ndef display_image(image, epoch):\n    \"\"\"\n    Displays the first image in the batch after every 5 epochs.\n    \n    Args:\n        image (numpy.ndarray): The image array to display.\n        epoch (int): The current epoch number.\n    \"\"\"\n    plt.figure(figsize=(4, 4))\n    plt.imshow((image * 127.5 + 127.5).astype(np.uint8))\n    plt.title(f\"Generated Image at Epoch {epoch}\")\n    plt.axis('off')\n    plt.show()\n\ndef train(predicted_image, cloth_images, mask_images, epochs):\n    dataset_size = len(predicted_image)  # Fixed the variable name\n    for epoch in range(epochs):\n        for i in range(0, dataset_size, BATCH_SIZE):\n            predicted_batch = predicted_image[i:i+BATCH_SIZE]\n            cloth_batch = cloth_images[i:i+BATCH_SIZE]\n            mask_batch = mask_images[i:i+BATCH_SIZE]\n            train_step(predicted_batch, cloth_batch, mask_batch)\n\n            # Generate images to visualize progress\n            if (i // BATCH_SIZE) % 10 == 0:  # Save every 10 steps\n                generated_cloths = generator([predicted_batch, mask_batch], training=False)\n                save_images(generated_cloths.numpy(), epoch, i // BATCH_SIZE)\n        \n        # Visualize the first image after every 5 epochs\n        if (epoch + 1) % 5 == 0:\n            generated_cloths = generator([predicted_image[:BATCH_SIZE], mask_images[:BATCH_SIZE]], training=False)\n            display_image(generated_cloths[0].numpy(), epoch + 1)\n                \n        print(f'Epoch {epoch + 1} completed')\n\n# Start training\ntrain(predicted_image, cloth_images, mask_images, EPOCHS)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T05:46:56.235581Z","iopub.execute_input":"2024-09-10T05:46:56.236095Z","iopub.status.idle":"2024-09-10T06:04:23.570234Z","shell.execute_reply.started":"2024-09-10T05:46:56.236048Z","shell.execute_reply":"2024-09-10T06:04:23.56906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine tuning with deeper model and gan approach\n\n## Can be ignored as GANs are computationally Expensive and might crash the session.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\ndef build_unet_virtual_tryon_model():\n    inputs_person = layers.Input(shape=(128, 128, 3))\n    inputs_cloth = layers.Input(shape=(128, 128, 3))\n    inputs_mask = layers.Input(shape=(128, 128, 1))\n\n    # Encoder for person image\n    x_person_og = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs_person)\n    x_person_skip = layers.MaxPooling2D((2, 2))(x_person_og)\n    x_person = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x_person_skip)\n    x_person = layers.MaxPooling2D((2, 2))(x_person)\n    x_person = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x_person)\n    x_person = layers.MaxPooling2D((2, 2))(x_person)\n\n    # Encoder for cloth image\n    x_cloth_og = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs_cloth)\n    x_cloth_skip = layers.MaxPooling2D((2, 2))(x_cloth_og)\n    x_cloth = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x_cloth_skip)\n    x_cloth_2 = layers.MaxPooling2D((2, 2))(x_cloth)\n    x_cloth = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x_cloth_2)\n    x_cloth = layers.MaxPooling2D((2, 2))(x_cloth)\n\n    # Encoder for segmentation mask\n    x_mask_og = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs_mask)\n    x_mask_skip = layers.MaxPooling2D((2, 2))(x_mask_og)\n    x_mask = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x_mask_skip)\n    x_mask = layers.MaxPooling2D((2, 2))(x_mask)\n    x_mask = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x_mask)\n    x_mask = layers.MaxPooling2D((2, 2))(x_mask)\n    \n    print(x_person.shape)\n    print(x_mask.shape)\n    print(x_cloth.shape)\n\n    # Concatenate features from all branches\n    concatenated = layers.concatenate([x_person, x_cloth, x_mask], axis=-1)\n    print(concatenated.shape)\n\n    # Decoder part with skip connections\n    x = layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(concatenated)\n    x = layers.concatenate([x, x_cloth_2], axis=-1)\n    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n\n    x = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(x)\n    print(x.shape)\n    x = layers.concatenate([x, x_cloth_skip], axis=-1)\n    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n\n    x = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.concatenate([x, x_person_og], axis=-1)\n    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n\n    # Output layer\n    output_image = layers.Conv2D(3, (1, 1), activation='sigmoid')(x)\n\n    # Build and compile the model\n    model = models.Model(inputs=[inputs_person, inputs_cloth, inputs_mask], outputs=output_image)\n    model.compile(optimizer='adam', loss='mse')  # Using MSE or perceptual loss\n\n    return model\n\n# Create and verify the generator\ngenerator = build_unet_virtual_tryon_model()\ngenerator.summary()\n\n# Verification Block: Checking the input and output shapes\nsample_person = tf.random.normal((1, 128, 128, 3))\nsample_cloth = tf.random.normal((1, 128, 128, 3))\nsample_mask = tf.random.normal((1, 128, 128, 1))\n\nsample_output = generator([sample_person, sample_cloth, sample_mask])\nprint(f\"Generator Input Shapes: {sample_person.shape}, {sample_cloth.shape}, {sample_mask.shape}\")\nprint(f\"Generator Output Shape: {sample_output.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T06:10:38.912786Z","iopub.execute_input":"2024-09-10T06:10:38.913614Z","iopub.status.idle":"2024-09-10T06:10:39.374347Z","shell.execute_reply.started":"2024-09-10T06:10:38.913565Z","shell.execute_reply":"2024-09-10T06:10:39.373063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Model has been built with {len(combined.layers)} layers.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T06:16:08.849377Z","iopub.execute_input":"2024-09-10T06:16:08.849814Z","iopub.status.idle":"2024-09-10T06:16:08.855732Z","shell.execute_reply.started":"2024-09-10T06:16:08.849774Z","shell.execute_reply":"2024-09-10T06:16:08.85454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers, models, optimizers\n\ndef build_discriminator():\n    inputs = layers.Input(shape=(128, 128, 3))\n\n    # Discriminator architecture\n    x = layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same')(inputs)\n    x = layers.LeakyReLU(alpha=0.2)(x)\n    x = layers.Dropout(0.3)(x)\n\n    x = layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same')(x)\n    x = layers.LeakyReLU(alpha=0.2)(x)\n    x = layers.Dropout(0.3)(x)\n\n    x = layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same')(x)\n    x = layers.LeakyReLU(alpha=0.2)(x)\n    x = layers.Dropout(0.3)(x)\n\n    x = layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same')(x)\n    x = layers.LeakyReLU(alpha=0.2)(x)\n    x = layers.Dropout(0.3)(x)\n\n    x = layers.Flatten()(x)\n    x = layers.Dense(1, activation='sigmoid')(x)\n\n    # Build and compile the discriminator\n    discriminator = models.Model(inputs, x)\n    discriminator.compile(optimizer=optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n\n    return discriminator\n\n# Create and verify the discriminator\ndiscriminator = build_discriminator()\ndiscriminator.summary()\n\n# Verification Block: Checking the input and output shapes\nsample_input = tf.random.normal((1, 128, 128, 3))  # A sample input\nsample_output = discriminator(sample_input)\nprint(f\"Discriminator Input Shape: {sample_input.shape}, Output Shape: {sample_output.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T06:13:51.070126Z","iopub.execute_input":"2024-09-10T06:13:51.070699Z","iopub.status.idle":"2024-09-10T06:13:51.232105Z","shell.execute_reply.started":"2024-09-10T06:13:51.070652Z","shell.execute_reply":"2024-09-10T06:13:51.230969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras import layers, optimizers\n\n# Freeze the discriminator when training the generator\ndiscriminator.trainable = False\n\n# Inputs for GAN\ninputs_person = layers.Input(shape=(128, 128, 3))\ninputs_cloth = layers.Input(shape=(128, 128, 3))\ninputs_mask = layers.Input(shape=(128, 128, 1))\n\n# Generator output\ngenerated_image = generator([inputs_person, inputs_cloth, inputs_mask])\n\n# Discriminator output on the generated image\nvalidity = discriminator(generated_image)\n\n# Combined model: Generator tries to fool the discriminator\ncombined = Model([inputs_person, inputs_cloth, inputs_mask], validity)\ncombined.compile(optimizer=optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n\ncombined.summary()\n\n# Verification Block: Checking if the combined model's output shape matches expected validity output\ncombined_output = combined([sample_person, sample_cloth, sample_mask])\nprint(f\"Combined Model Output Shape: {combined_output.shape}\")  # Expected to be (batch_size, 1)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T06:14:17.290306Z","iopub.execute_input":"2024-09-10T06:14:17.291503Z","iopub.status.idle":"2024-09-10T06:14:17.521653Z","shell.execute_reply.started":"2024-09-10T06:14:17.29145Z","shell.execute_reply":"2024-09-10T06:14:17.520499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\ndef visualize_results(generator, input_data, real_images, num_samples=5, epoch=None):\n    \"\"\"\n    Visualize real and generated images side by side to evaluate quality.\n\n    Args:\n        generator: Trained generator model.\n        input_data: Tuple containing (input_person, input_cloth, input_mask).\n        real_images: Ground truth images for comparison.\n        num_samples: Number of samples to visualize.\n        epoch: Current epoch number for labeling (optional).\n    \"\"\"\n    # Generate images using the generator\n    generated_images = generator.predict(input_data)\n\n    # Select random samples for visualization\n    indices = np.random.choice(range(len(real_images)), num_samples, replace=False)\n\n    # Plot real vs generated images\n    plt.figure(figsize=(12, num_samples * 2))\n\n    for i, idx in enumerate(indices):\n        # Real image\n        plt.subplot(num_samples, 2, i * 2 + 1)\n        plt.imshow(real_images[idx])\n        plt.title(\"Real Image\")\n        plt.axis('off')\n\n        # Generated image\n        plt.subplot(num_samples, 2, i * 2 + 2)\n        plt.imshow(generated_images[idx])\n        plt.title(\"Generated Image\")\n        plt.axis('off')\n\n    plt.tight_layout()\n    if epoch is not None:\n        plt.suptitle(f'Epoch {epoch}', fontsize=16)\n    plt.show()\n\n    # Optionally, save images\n    plt.savefig(f'generated_images_epoch_{epoch}.png')\n\ndef train_gan(generator, discriminator, combined, epochs, batch_size, X_person, X_cloth, X_mask, Y_output):\n    num_samples = X_person.shape[0]\n    steps_per_epoch = num_samples // batch_size\n\n    for epoch in range(epochs):\n        for batch_i in range(steps_per_epoch):\n            # Prepare a batch of data\n            start_idx = batch_i * batch_size\n            end_idx = start_idx + batch_size\n            \n            # Slice the arrays to get the batch data\n            batch_person = X_person[start_idx:end_idx]\n            batch_cloth = X_cloth[start_idx:end_idx]\n            batch_mask = X_mask[start_idx:end_idx]\n            real_images = Y_output[start_idx:end_idx]\n\n            # Combine inputs for generator\n            input_data = [batch_person, batch_cloth, batch_mask]\n\n            # Generate fake images using the generator\n            fake_images = generator.predict(input_data)\n\n            # Create labels: 1 for real images, 0 for fake images\n            real_labels = np.ones((batch_size, 1))  # Label real images as 1\n            fake_labels = np.zeros((batch_size, 1))  # Label generated images as 0\n\n            # Train discriminator on real images\n            d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n\n            # Train discriminator on generated (fake) images\n            d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n\n            # Calculate the average loss for the discriminator\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n            # Verification Block: Check discriminator accuracy after each batch\n            print(f\"Discriminator Accuracy: {d_loss[1] * 100:.2f}% on batch {batch_i+1}\")\n\n            # Prepare labels for generator training: all labels should be real (1)\n            misleading_labels = np.ones((batch_size, 1))\n\n            # Train the generator via the combined model\n            g_loss = combined.train_on_batch(input_data, misleading_labels)\n\n            # Extract the primary loss value if g_loss is a list or array\n            if isinstance(g_loss, (list, np.ndarray)):\n                primary_g_loss = g_loss[0]  # Access the primary loss value\n            else:\n                primary_g_loss = g_loss\n\n            # Verification Block: Log generator loss after each batch\n            print(f\"Generator Loss: {primary_g_loss:.4f} on batch {batch_i+1}\")\n\n        # Epoch summary\n        print(f\"Epoch {epoch+1}/{epochs} | D Loss: {d_loss[0]:.4f} | D Acc: {100 * d_loss[1]:.2f}% | G Loss: {primary_g_loss:.4f}\")\n\n        # Visualize results after each epoch\n        visualize_results(generator, input_data, real_images, num_samples=5, epoch=epoch + 1)\n\n    # Save final generated images for evaluation\n    print(\"Training complete. Generating final images for evaluation...\")\n    visualize_results(generator, [X_person, X_cloth, X_mask], Y_output, num_samples=10, epoch=\"final\")\n\n\n# Define the number of epochs and batch size\nepochs = 10\nbatch_size = 32\n\n# Call the training function\ntrain_gan(generator, discriminator, combined, epochs, batch_size, X_person, X_cloth, X_segmentation, Y_output)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T06:46:55.518837Z","iopub.execute_input":"2024-09-10T06:46:55.51934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the number of epochs and batch size\nepochs = 10\nbatch_size = 32\n\n# Example data initialization (replace with actual data)\n# X_person = np.random.rand(500, 128, 128, 3)\n# X_cloth = np.random.rand(500, 128, 128, 3)\n# X_mask = np.random.rand(500, 128, 128, 1)\n# Y_output = np.random.rand(500, 128, 128, 3)\n\n# Call the training function\ntrain_gan(generator, discriminator, combined, epochs, batch_size, X_person, X_cloth, X_segmentation, Y_output)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T06:33:12.17831Z","iopub.execute_input":"2024-09-10T06:33:12.179032Z","iopub.status.idle":"2024-09-10T06:33:39.432445Z","shell.execute_reply.started":"2024-09-10T06:33:12.178983Z","shell.execute_reply":"2024-09-10T06:33:39.430848Z"},"trusted":true},"execution_count":null,"outputs":[]}]}